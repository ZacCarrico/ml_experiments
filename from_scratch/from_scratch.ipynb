{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to understand the basics of neural networks.\n",
    "\n",
    "We will start with a single neuron and then move on to a simple neural network.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=Model(\n",
      "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the linear layer (single neuron)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "# Create an instance of the model\n",
    "model = Model()\n",
    "print(f\"{model=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:\n",
      "linear.weight: tensor([[-0.0075]])\n",
      "linear.bias: tensor([0.5364])\n",
      "model(torch.tensor([1.0]))=tensor([0.5290], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the model parameters\n",
    "print(\"Model parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")\n",
    "print(f\"{model(torch.tensor([1.0]))=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the model for the input of 1.0 is a tensor with a single value that is the result of a random initialization of the weights and biases.\n",
    "The output is 0.5290, which is input * weight + bias: 1.0 * -0.0075 + 0.5364 = 0.5289. This is slightly different than 0.5290 b/c the printed values are rounded from the actual float values used.\n",
    "\n",
    "By default, autograd is tracking the operations that are performed on the model.\n",
    "`grad_fn=<ViewBackward0>` tells us that the last operation to create this output was a view operation. Without the view operation the output would have been [[0.5290]] rather than [0.5290]. The `Backward` means that during backgpropagation the Backward function will be called. The `0` suffix means that this will be the first backward call.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 0.5289567708969116,\n",
       " 'loss': 0.2218817174434662,\n",
       " 'weight': 0.08672183007001877,\n",
       " 'bias': 0.6306522488594055,\n",
       " 'weight_grad': -0.9420864582061768,\n",
       " 'bias_grad': -0.9420864582061768}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a simple training example\n",
    "def train_step(x: torch.Tensor, y: torch.Tensor) -> None:\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()  # This computes gradients for all model parameters\n",
    "    optimizer.step()  # This uses the gradients to update the weights and biases\n",
    "    weight_grad = model.linear.weight.grad.item()\n",
    "    bias_grad = model.linear.bias.grad.item()\n",
    "    # Reset gradients for the next step\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Return values for tabulation\n",
    "    return {\n",
    "        'prediction': output.item(),\n",
    "        'loss': loss.item(),\n",
    "        'weight': model.linear.weight.data.item(),\n",
    "        'bias': model.linear.bias.data.item(),\n",
    "        'weight_grad': weight_grad,\n",
    "        'bias_grad': bias_grad\n",
    "    }\n",
    "first_result = train_step(x=torch.tensor([1.0]), y=torch.tensor([1.0]))\n",
    "first_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the loss is ~0.22 which is calculated from the MSE: (1-0.5289)^2 = 0.2219.  \n",
    "The new gradients are the result of the optimizer updating the weights and biases.  \n",
    "For MSELoss, the gradient is ∂Loss/∂output = 2 * (output - target) / n, which is 2 * (0.5289 - 1) / 1 = -0.9422 for the weight and bias (not shown). This is then used to update the weights and biases from above:  \n",
    "new weight = old_weight - learning_rate * gradient_weight = -0.0075 - 0.01 * -0.9422 = 0.0019  \n",
    "new bias = old_bias - learning_rate * gradient_bias = 0.5364 - 0.01 * -0.9422 = 0.5458\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>prediction</th>\n",
       "      <th>loss</th>\n",
       "      <th>weight</th>\n",
       "      <th>bias</th>\n",
       "      <th>weight_grad</th>\n",
       "      <th>bias_grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.528957</td>\n",
       "      <td>2.218817e-01</td>\n",
       "      <td>0.086722</td>\n",
       "      <td>0.630652</td>\n",
       "      <td>-9.420865e-01</td>\n",
       "      <td>-9.420865e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.717374</td>\n",
       "      <td>7.987741e-02</td>\n",
       "      <td>0.143247</td>\n",
       "      <td>0.687177</td>\n",
       "      <td>-5.652518e-01</td>\n",
       "      <td>-5.652518e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.830424</td>\n",
       "      <td>2.875588e-02</td>\n",
       "      <td>0.177162</td>\n",
       "      <td>0.721093</td>\n",
       "      <td>-3.391511e-01</td>\n",
       "      <td>-3.391511e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.898255</td>\n",
       "      <td>1.035212e-02</td>\n",
       "      <td>0.197511</td>\n",
       "      <td>0.741442</td>\n",
       "      <td>-2.034907e-01</td>\n",
       "      <td>-2.034907e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.938953</td>\n",
       "      <td>3.726760e-03</td>\n",
       "      <td>0.209721</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-1.220944e-01</td>\n",
       "      <td>-1.220944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.963372</td>\n",
       "      <td>1.341637e-03</td>\n",
       "      <td>0.217046</td>\n",
       "      <td>0.760977</td>\n",
       "      <td>-7.325673e-02</td>\n",
       "      <td>-7.325673e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.978023</td>\n",
       "      <td>4.829889e-04</td>\n",
       "      <td>0.221442</td>\n",
       "      <td>0.765372</td>\n",
       "      <td>-4.395401e-02</td>\n",
       "      <td>-4.395401e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.986814</td>\n",
       "      <td>1.738763e-04</td>\n",
       "      <td>0.224079</td>\n",
       "      <td>0.768009</td>\n",
       "      <td>-2.637243e-02</td>\n",
       "      <td>-2.637243e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.992088</td>\n",
       "      <td>6.259471e-05</td>\n",
       "      <td>0.225661</td>\n",
       "      <td>0.769592</td>\n",
       "      <td>-1.582336e-02</td>\n",
       "      <td>-1.582336e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.995253</td>\n",
       "      <td>2.253432e-05</td>\n",
       "      <td>0.226611</td>\n",
       "      <td>0.770541</td>\n",
       "      <td>-9.494066e-03</td>\n",
       "      <td>-9.494066e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>8.112289e-06</td>\n",
       "      <td>0.227180</td>\n",
       "      <td>0.771111</td>\n",
       "      <td>-5.696416e-03</td>\n",
       "      <td>-5.696416e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>2.920424e-06</td>\n",
       "      <td>0.227522</td>\n",
       "      <td>0.771452</td>\n",
       "      <td>-3.417850e-03</td>\n",
       "      <td>-3.417850e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.998975</td>\n",
       "      <td>1.051401e-06</td>\n",
       "      <td>0.227727</td>\n",
       "      <td>0.771658</td>\n",
       "      <td>-2.050757e-03</td>\n",
       "      <td>-2.050757e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>3.785192e-07</td>\n",
       "      <td>0.227850</td>\n",
       "      <td>0.771781</td>\n",
       "      <td>-1.230478e-03</td>\n",
       "      <td>-1.230478e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>1.362581e-07</td>\n",
       "      <td>0.227924</td>\n",
       "      <td>0.771854</td>\n",
       "      <td>-7.382631e-04</td>\n",
       "      <td>-7.382631e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>4.905820e-08</td>\n",
       "      <td>0.227968</td>\n",
       "      <td>0.771899</td>\n",
       "      <td>-4.429817e-04</td>\n",
       "      <td>-4.429817e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.999867</td>\n",
       "      <td>1.765145e-08</td>\n",
       "      <td>0.227995</td>\n",
       "      <td>0.771925</td>\n",
       "      <td>-2.657175e-04</td>\n",
       "      <td>-2.657175e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>6.360224e-09</td>\n",
       "      <td>0.228011</td>\n",
       "      <td>0.771941</td>\n",
       "      <td>-1.595020e-04</td>\n",
       "      <td>-1.595020e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>2.285120e-09</td>\n",
       "      <td>0.228020</td>\n",
       "      <td>0.771951</td>\n",
       "      <td>-9.560585e-05</td>\n",
       "      <td>-9.560585e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>8.253807e-10</td>\n",
       "      <td>0.228026</td>\n",
       "      <td>0.771957</td>\n",
       "      <td>-5.745888e-05</td>\n",
       "      <td>-5.745888e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>2.967262e-10</td>\n",
       "      <td>0.228030</td>\n",
       "      <td>0.771960</td>\n",
       "      <td>-3.445148e-05</td>\n",
       "      <td>-3.445148e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>1.063292e-10</td>\n",
       "      <td>0.228032</td>\n",
       "      <td>0.771962</td>\n",
       "      <td>-2.062321e-05</td>\n",
       "      <td>-2.062321e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>3.842615e-11</td>\n",
       "      <td>0.228033</td>\n",
       "      <td>0.771963</td>\n",
       "      <td>-1.239777e-05</td>\n",
       "      <td>-1.239777e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.365663e-11</td>\n",
       "      <td>0.228034</td>\n",
       "      <td>0.771964</td>\n",
       "      <td>-7.390976e-06</td>\n",
       "      <td>-7.390976e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>5.130119e-12</td>\n",
       "      <td>0.228034</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-4.529953e-06</td>\n",
       "      <td>-4.529953e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.719513e-12</td>\n",
       "      <td>0.228034</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-2.622604e-06</td>\n",
       "      <td>-2.622604e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>6.963319e-13</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-1.668930e-06</td>\n",
       "      <td>-1.668930e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.273737e-13</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.684342e-14</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-4.768372e-07</td>\n",
       "      <td>-4.768372e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.421085e-14</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-2.384186e-07</td>\n",
       "      <td>-2.384186e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.421085e-14</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-2.384186e-07</td>\n",
       "      <td>-2.384186e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.421085e-14</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-2.384186e-07</td>\n",
       "      <td>-2.384186e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.552714e-15</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.552714e-15</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.228035</td>\n",
       "      <td>0.771965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration  prediction          loss    weight      bias   weight_grad  \\\n",
       "0           0    0.528957  2.218817e-01  0.086722  0.630652 -9.420865e-01   \n",
       "1           1    0.717374  7.987741e-02  0.143247  0.687177 -5.652518e-01   \n",
       "2           2    0.830424  2.875588e-02  0.177162  0.721093 -3.391511e-01   \n",
       "3           3    0.898255  1.035212e-02  0.197511  0.741442 -2.034907e-01   \n",
       "4           4    0.938953  3.726760e-03  0.209721  0.753651 -1.220944e-01   \n",
       "5           5    0.963372  1.341637e-03  0.217046  0.760977 -7.325673e-02   \n",
       "6           6    0.978023  4.829889e-04  0.221442  0.765372 -4.395401e-02   \n",
       "7           7    0.986814  1.738763e-04  0.224079  0.768009 -2.637243e-02   \n",
       "8           8    0.992088  6.259471e-05  0.225661  0.769592 -1.582336e-02   \n",
       "9           9    0.995253  2.253432e-05  0.226611  0.770541 -9.494066e-03   \n",
       "10         10    0.997152  8.112289e-06  0.227180  0.771111 -5.696416e-03   \n",
       "11         11    0.998291  2.920424e-06  0.227522  0.771452 -3.417850e-03   \n",
       "12         12    0.998975  1.051401e-06  0.227727  0.771658 -2.050757e-03   \n",
       "13         13    0.999385  3.785192e-07  0.227850  0.771781 -1.230478e-03   \n",
       "14         14    0.999631  1.362581e-07  0.227924  0.771854 -7.382631e-04   \n",
       "15         15    0.999779  4.905820e-08  0.227968  0.771899 -4.429817e-04   \n",
       "16         16    0.999867  1.765145e-08  0.227995  0.771925 -2.657175e-04   \n",
       "17         17    0.999920  6.360224e-09  0.228011  0.771941 -1.595020e-04   \n",
       "18         18    0.999952  2.285120e-09  0.228020  0.771951 -9.560585e-05   \n",
       "19         19    0.999971  8.253807e-10  0.228026  0.771957 -5.745888e-05   \n",
       "20         20    0.999983  2.967262e-10  0.228030  0.771960 -3.445148e-05   \n",
       "21         21    0.999990  1.063292e-10  0.228032  0.771962 -2.062321e-05   \n",
       "22         22    0.999994  3.842615e-11  0.228033  0.771963 -1.239777e-05   \n",
       "23         23    0.999996  1.365663e-11  0.228034  0.771964 -7.390976e-06   \n",
       "24         24    0.999998  5.130119e-12  0.228034  0.771965 -4.529953e-06   \n",
       "25         25    0.999999  1.719513e-12  0.228034  0.771965 -2.622604e-06   \n",
       "26         26    0.999999  6.963319e-13  0.228035  0.771965 -1.668930e-06   \n",
       "27         27    1.000000  2.273737e-13  0.228035  0.771965 -9.536743e-07   \n",
       "28         28    1.000000  5.684342e-14  0.228035  0.771965 -4.768372e-07   \n",
       "29         29    1.000000  1.421085e-14  0.228035  0.771965 -2.384186e-07   \n",
       "30         30    1.000000  1.421085e-14  0.228035  0.771965 -2.384186e-07   \n",
       "31         31    1.000000  1.421085e-14  0.228035  0.771965 -2.384186e-07   \n",
       "32         32    1.000000  3.552714e-15  0.228035  0.771965 -1.192093e-07   \n",
       "33         33    1.000000  3.552714e-15  0.228035  0.771965 -1.192093e-07   \n",
       "34         34    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "35         35    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "36         36    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "37         37    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "38         38    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "39         39    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "40         40    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "41         41    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "42         42    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "43         43    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "44         44    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "45         45    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "46         46    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "47         47    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "48         48    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "49         49    1.000000  0.000000e+00  0.228035  0.771965  0.000000e+00   \n",
       "\n",
       "       bias_grad  \n",
       "0  -9.420865e-01  \n",
       "1  -5.652518e-01  \n",
       "2  -3.391511e-01  \n",
       "3  -2.034907e-01  \n",
       "4  -1.220944e-01  \n",
       "5  -7.325673e-02  \n",
       "6  -4.395401e-02  \n",
       "7  -2.637243e-02  \n",
       "8  -1.582336e-02  \n",
       "9  -9.494066e-03  \n",
       "10 -5.696416e-03  \n",
       "11 -3.417850e-03  \n",
       "12 -2.050757e-03  \n",
       "13 -1.230478e-03  \n",
       "14 -7.382631e-04  \n",
       "15 -4.429817e-04  \n",
       "16 -2.657175e-04  \n",
       "17 -1.595020e-04  \n",
       "18 -9.560585e-05  \n",
       "19 -5.745888e-05  \n",
       "20 -3.445148e-05  \n",
       "21 -2.062321e-05  \n",
       "22 -1.239777e-05  \n",
       "23 -7.390976e-06  \n",
       "24 -4.529953e-06  \n",
       "25 -2.622604e-06  \n",
       "26 -1.668930e-06  \n",
       "27 -9.536743e-07  \n",
       "28 -4.768372e-07  \n",
       "29 -2.384186e-07  \n",
       "30 -2.384186e-07  \n",
       "31 -2.384186e-07  \n",
       "32 -1.192093e-07  \n",
       "33 -1.192093e-07  \n",
       "34  0.000000e+00  \n",
       "35  0.000000e+00  \n",
       "36  0.000000e+00  \n",
       "37  0.000000e+00  \n",
       "38  0.000000e+00  \n",
       "39  0.000000e+00  \n",
       "40  0.000000e+00  \n",
       "41  0.000000e+00  \n",
       "42  0.000000e+00  \n",
       "43  0.000000e+00  \n",
       "44  0.000000e+00  \n",
       "45  0.000000e+00  \n",
       "46  0.000000e+00  \n",
       "47  0.000000e+00  \n",
       "48  0.000000e+00  \n",
       "49  0.000000e+00  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame from the first training result\n",
    "results_df = pd.DataFrame([first_result])\n",
    "# Add an iteration column and set it to 0\n",
    "results_df.insert(0, 'iteration', 0)\n",
    "\n",
    "for i in range(1, 50):\n",
    "    result = train_step(x=torch.tensor([1.0]), y=torch.tensor([1.0]))\n",
    "    # Create a new row with the current iteration and result\n",
    "    new_row = pd.DataFrame([{**{'iteration': i}, **result}])\n",
    "    # Append the new row to results_df\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
